{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81fe0b4-f5d7-4a9a-ab27-c2766cf3cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from load_csv import CSV_Loader\n",
    "from configs.configuration import general_config, dataset_config\n",
    "import pandas as pd\n",
    "import glob\n",
    "import dask.dataframe as dd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a30a34e2-f99d-42b7-a403-bae941e49493",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class _Loader:\n",
    "    \"\"\"\n",
    "    Interface that loads all the data into the memory\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            pass\n",
    "            \n",
    "        except Exception as e:\n",
    "            display(\"Error occured in initialization of _Loader interface due to \", e)\n",
    "                \n",
    "        finally:\n",
    "            display(\"Loader Interface initialized\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_file():\n",
    "        raise NotImplementedError    \n",
    "\n",
    "\n",
    "class CSV_Loader(_Loader):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            super().__init__()\n",
    "        \n",
    "        except Exception as e:\n",
    "            display(\"Error occured in initialization of CSV_Loader class due to \", e)\n",
    "                \n",
    "        finally:\n",
    "            display(\"CSV_Loader initialized\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def _load_file(csv_file_path,\n",
    "                   index_column_name=None,\n",
    "                   _nrows=None,\n",
    "                   _iterator=True,\n",
    "                   _chunksize=100000):\n",
    "        try:\n",
    "            tp = pd.read_csv(csv_file_path, nrows=_nrows, index_col=index_column_name, iterator=_iterator, chunksize=_chunksize) ## loading data in chunks reduces 90 percent execution time \n",
    "            df = pd.concat(tp, ignore_index=False)\n",
    "            df.info(verbose=False, memory_usage=\"deep\")\n",
    "            return df  \n",
    "        \n",
    "        except Exception as e:\n",
    "            display(\"Error occured in _load_file method of CSV_Loader class due to \", e)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_file_via_dask(csv_file_path,\n",
    "                            fetch_houses=[1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20,21]):\n",
    "        try:\n",
    "            ls = {}\n",
    "            display(f\"Loading specified houses: {fetch_houses}\")\n",
    "            for i in fetch_houses:\n",
    "                ls.update({i: dd.read_csv(f'{csv_file_path}House_{i}.csv')})\n",
    "                \n",
    "            return ls\n",
    "        \n",
    "        except Exception as e:\n",
    "            display(\"Error occured in _load_file_via_dask method of CSV_Loader class due to \", e)\n",
    "            \n",
    "            \n",
    "    ###### appliance wise Dict Reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6db187f5-3273-4e83-9543-1eaf54b56409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parser(readme_file):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        display(f'Loading the readme files specified: {readme_file}')\n",
    "        with open(readme_file) as f:\n",
    "            content = f.readlines()\n",
    "        ls = {}\n",
    "        for i, s in enumerate(content):\n",
    "            if 'House' in s.capitalize():\n",
    "                keys, appliances = [], []\n",
    "                house = s.split()[1]\n",
    "                for indx in range(1, 6):\n",
    "                    if content[i+indx] == '\\t!NOTES\\n':\n",
    "                        break\n",
    "                    else:\n",
    "                        target = [value.split('.') for value in [value for value in content[i+indx].split(',') if value != '\\n']]\n",
    "                        for t in target:\n",
    "                            if len(t) > 2: ##### one comma missing caused issue\n",
    "                                appliances.append(t[1])\n",
    "                                appliances.append(t[2])\n",
    "                            else:\n",
    "                                appliances.append(t[1])\n",
    "                ls.update({house: [item.split('\\n')[0] for item in appliances]})\n",
    "        return ls\n",
    "    \n",
    "    except Exception as e:\n",
    "        display(\"Error occured in parser method due to \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4629c85d-1fe0-48af-9c87-d5a727f5bd3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loader Interface initialized'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'CSV_Loader initialized'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ob = CSV_Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "908cd34c-a862-4fcb-8335-1b7100fb8fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loading specified houses: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 480 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "collective_dataset = ob._load_file_via_dask(csv_file_path=general_config['DATA_FOLDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd768483-abd0-42e5-a488-045e0f505f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Loading the readme files specified: data/refit/REFIT_Readme.txt'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keys_of_appliances = parser(general_config['README_FILE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14676015-31c3-48a5-891c-4fa4af9be7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for house_number in collective_dataset:\n",
    "    cols = keys_of_appliances[str(house_number)]\n",
    "    collective_dataset[house_number] = collective_dataset[house_number].rename(columns={\"Appliance1\":cols[1], \"Appliance2\":cols[2], \"Appliance3\":cols[3], \"Appliance4\":cols[4], \"Appliance5\":cols[5],\n",
    "                                       \"Appliance6\":cols[6], \"Appliance7\":cols[7], \"Appliance8\":cols[8], \"Appliance9\":cols[9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b290f215-eb7e-471d-9c3d-025f2fdfc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_house_data(house_number):\n",
    "    return collective_dataset[house_number].compute()\n",
    "    \n",
    "def get_appliance_data(target_appliance, houses='all_houses'):\n",
    "    ls = {}\n",
    "    if houses == 'all_houses':\n",
    "        for house_number in range(1, len(collective_dataset)+1):\n",
    "            print(house_number)\n",
    "            if target_appliance in collective_dataset[house_number].columns:\n",
    "                data = collective_dataset[house_number][['Time', target_appliance]].compute()\n",
    "                ls.update({house_number: data})\n",
    "    elif type(houses) == list and len(houses)!=0:\n",
    "        for house_number in houses:\n",
    "            if target_appliance in collective_dataset[house_number].columns:\n",
    "                display(f'Fetching data for House {house_number}')\n",
    "                data = collective_dataset[house_number][['Time', target_appliance]].compute()\n",
    "                ls.update({house_number: data})\n",
    "    else:\n",
    "        raise Exception(\"argument 'houses' should not be an empty list or by default set should be set to 'all_houses'\")\n",
    "    \n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "43b5a2a0-95f6-47d5-8b39-2addae45fb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HOUSE_1 = get_house_data(1)\n",
    "# HOUSE_2 = get_house_data(2)\n",
    "# HOUSE_3 = get_house_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "46fe4769-3b3a-4967-9dfb-6c122c869d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 2'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 3'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 4'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 5'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 6'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 7'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Fetching data for House 8'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "KETTLE = get_appliance_data(\"Kettle\", houses=[1,2,3,4,5,6,7,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5794481a-60e5-456f-a437-03bf63652d94",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-068cea0bfce8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mKETTLE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "KETTLE[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e265b-03a9-4c08-ab54-2db36f4fb3ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf07ad-ddef-4991-9457-ce2fb081d856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa23b28-6643-4efe-be2d-849d3cd863fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d81113-c403-47e3-9279-55ebc8fc4026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0446844f-ab6f-47da-8d42-b610c991a8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef62be-e3eb-47f8-b4d9-55d582038b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cdf58a-eaca-4f12-a099-c7355a09cd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c978b-45ab-4bc4-841e-29a34d4350b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7099000b-2850-4e46-9077-cc12c9506099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff5105-e0e9-4972-b2d5-90bfe10f7264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
